In the 21st century, where we find artificial intelligence used in every aspect of our everyday lives, machine learning and artificial intelligence has become more than just the next buzz word to catch the attention of the public. From software like the Amazon Alexa and Apple’s Siri which uses users’ personal data in order to improve on itself, software like Google’s search bar which builds upon the user’s search preferences in order to match them with the correct amount of queries, may seem like algorithms of low ethical impact, but there are use cases as well which have direct impact on society, particularly in the face of government and socio economic relationships. As such, these examples go to show it is even more important to pay attention to the ethical impacts of technology, most particularly concerning the governments and making sure that AI is developed and used responsibly.
From the standpoint of the development of artificial intelligence, it is intended to simplify tasks and advance the completion of tasks. With governmental traction, policy oversight is still in its infancy. The United States government already has some plan on what agencies can police and regulate the use of artificial intelligence; AI in healthcare: FDA, AI in autonomous vehicles: Department of Transportation. However, for social media platforms, there is no regulation or department in place. In vulnerable times in United States history, such as “during the 2016 U.S. presidential elections, Russian operatives took advantage of social media to target Black people, spreading messages seeking to incite racial conflict and discourage Black people from going to the ballot box” (Lee & Lai, 2022). This form of modern voter suppression was allowed to continue, since the government did not have any rules in place. It is easy to see how this might have an impact on society. Furthermore, another aspect of social media comes from the impact that it has on the body image of impressionable young users. For example, a report from the National Institute of Health details the dangers of media on children and adolescents, mentioning that looking at models I the media, they “develop[ed] weight concerns and bec[a]me constant dieters” (Morris & Katzman, 2003). Seeing how social media is being used on impressionable young minds to gain money corporations, it is only right for governments to have rules and regulations in place to control what type of media and ideals are presented to users of certain age groups.
On the other side of regulation, is use of technology. In SQ7.B, it is mentioned that artificial intelligence is being used to produce lethal autonomous weapon systems (LAWS). It is difficult to understand why artificial intelligence is being used in a position which is doing more harm than help. In the military, soldiers can see the human cost of firing their weapon, but controlling these systems remotely, operators are unable to feel the moral cost of their decision. In addition, experts at the Future of Life Institute indicate that LAWS would “be disproportionately useful for ethnic cleansing and genocide” (Piper, 2019). As such, it is hard to see why society should put AI to use in LAWS.
However, the future development of artificial intelligence rests on how it is used, especially in places of social and ethical impact. By bringing awareness to the issue, which is the government’s use of artificial intelligence, citizens will be able to understand and advocate for further regulation or deregulation of this new technology.
